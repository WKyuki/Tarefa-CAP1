{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087b46eb",
   "metadata": {},
   "source": [
    "\n",
    "# FarmTech Solutions — Fase 5 (Entrega 1: Machine Learning)\n",
    "**Aluno:** _substitua pelo seu nome_  \n",
    "**Disciplina:** IA Aplicada ao Agronegócio  \n",
    "**Objetivo:** Prever **Rendimento (t/ha)** e explorar **tendências de produtividade** via **clusterização**, com **boas práticas de ML**.\n",
    "\n",
    "---\n",
    "\n",
    "### O que este notebook faz\n",
    "1. **Carrega os dados** `crop_yield.csv` (ou gera um dataset sintético compatível, caso o arquivo não esteja disponível).\n",
    "2. **EDA:** estatísticas, checagens, correlações e gráficos.\n",
    "3. **Tendências & Outliers:** KMeans, DBSCAN, PCA e detecção de outliers (IQR e IsolationForest).\n",
    "4. **Modelagem (Regressão):** 5 algoritmos diferentes, com `Pipeline`, `ColumnTransformer`, validação, ajuste e **comparação de métricas**.\n",
    "5. **Seleção & Exportação:** escolhe o melhor modelo e salva em `models/best_model.pkl`. Exporta métricas e predições.\n",
    "6. **Reprodutibilidade:** semente aleatória, funções utilitárias e logs básicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports essenciais\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Pré-processamento e modelagem\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Modelos de Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, IsolationForest\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Validação e Métricas\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Clusterização e Redução de Dimensionalidade\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Util\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "BASE_DIR = Path('/mnt/data/FarmTech_Fase5_Entrega1')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "MODELS_DIR = BASE_DIR / 'models'\n",
    "REPORTS_DIR = BASE_DIR / 'reports'\n",
    "ARTIFACTS_DIR = BASE_DIR / 'artifacts'\n",
    "DATA_PATH = DATA_DIR / 'crop_yield.csv'  # esperado no portal\n",
    "SYNTH_PATH = DATA_DIR / 'crop_yield_sample.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f916535",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Carregamento dos dados\n",
    "Tente carregar `data/crop_yield.csv`. Se não existir, geramos um dataset **sintético** com o mesmo esquema para facilitar a execução e a validação do pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_synthetic_dataset(n=600, n_culturas=5, random_state=RANDOM_STATE):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    culturas = [f'Cultura_{i+1}' for i in range(n_culturas)]\n",
    "    cultura = rng.choice(culturas, size=n, replace=True)\n",
    "\n",
    "    # Variáveis climáticas/solo (valores plausíveis, mas sintéticos)\n",
    "    precipitacao = rng.normal(4.0, 2.0, size=n).clip(0, 20)  # mm/dia\n",
    "    umid_espec = rng.normal(7.0, 1.8, size=n).clip(2, 15)    # g/kg\n",
    "    umid_rel = rng.normal(65, 15, size=n).clip(10, 100)      # %\n",
    "    temp2m = rng.normal(22, 6, size=n).clip(-2, 42)          # ºC\n",
    "\n",
    "    # Relação não-linear com ruído + efeito por cultura\n",
    "    base_yield = (\n",
    "        0.8*precipitacao\n",
    "        + 0.3*umid_espec\n",
    "        - 0.15*np.maximum(temp2m-28, 0)**2 / 10  # penalidade calor extremo\n",
    "        + 0.02*umid_rel\n",
    "    )\n",
    "    efeitos_cultura = {c: rng.normal(3.0 + i*0.5, 0.4) for i, c in enumerate(culturas)}\n",
    "    rendimento = np.array([base_yield[i] + efeitos_cultura[cultura[i]] + rng.normal(0, 0.8) for i in range(n)])\n",
    "    rendimento = rendimento.clip(0.5, None)  # t/ha\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Cultura': cultura,\n",
    "        'Precipitação (mm dia 1)': precipitacao.round(2),\n",
    "        'Umidade específica a 2 metros (g/kg)': umid_espec.round(2),\n",
    "        'Umidade relativa a 2 metros (%)': umid_rel.round(1),\n",
    "        'Temperatura a 2 metros (ºC)': temp2m.round(1),\n",
    "        'Rendimento': rendimento.round(2)\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# Carregar ou gerar\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    origem = 'Arquivo fornecido (crop_yield.csv)'\n",
    "else:\n",
    "    df = generate_synthetic_dataset()\n",
    "    df.to_csv(SYNTH_PATH, index=False)\n",
    "    origem = 'Dataset sintético gerado (crop_yield_sample.csv)'\n",
    "print('Origem dos dados:', origem)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f721b",
   "metadata": {},
   "source": [
    "\n",
    "## 2. EDA — Análise Exploratória de Dados\n",
    "Verificações essenciais: dimensões, tipos, valores ausentes, estatísticas descritivas e correlações.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Formato:', df.shape)\n",
    "print('\\nTipos:\\n', df.dtypes)\n",
    "print('\\nValores ausentes por coluna:\\n', df.isna().sum())\n",
    "\n",
    "display_cols = [c for c in df.columns if c != 'Cultura']\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "# Distribuições (histogramas) — sem seaborn, um gráfico por chamada\n",
    "for col in display_cols:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=30)\n",
    "    plt.title(f'Distribuição de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.show()\n",
    "\n",
    "# Correlação numérica\n",
    "num_cols = [c for c in df.columns if df[c].dtype != 'O' and c != 'Rendimento'] + ['Rendimento']\n",
    "corr = df[num_cols].corr()\n",
    "plt.figure()\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.xticks(range(len(num_cols)), num_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(num_cols)), num_cols)\n",
    "plt.title('Matriz de Correlação (numéricas)')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "corr['Rendimento'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f6c490",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Tendências de Produtividade e Outliers (Sem Supervisão)\n",
    "Aplicamos **PCA** para 2D, **KMeans** (k=3..6) e **DBSCAN** para ver padrões de produtividade. Outliers via **IQR** e **IsolationForest**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecionar features numéricas para clusterização\n",
    "features = ['Precipitação (mm dia 1)', 'Umidade específica a 2 metros (g/kg)',\n",
    "            'Umidade relativa a 2 metros (%)', 'Temperatura a 2 metros (ºC)', 'Rendimento']\n",
    "X_unsup = df[features].copy()\n",
    "\n",
    "# Padronizar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_unsup)\n",
    "\n",
    "# PCA 2D\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print('Variância explicada (2D):', pca.explained_variance_ratio_.sum())\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], s=12)\n",
    "plt.title('PCA (2D) — Dados padronizados')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n",
    "\n",
    "# KMeans para vários k e inércia (elbow)\n",
    "inertias = []\n",
    "k_range = range(3, 7)\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=10)\n",
    "    km.fit(X_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(k_range), inertias, marker='o')\n",
    "plt.title('KMeans: Curva do Cotovelo (Inertia)')\n",
    "plt.xlabel('k'); plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n",
    "# Escolher k=4 (ajuste prático); você pode variar\n",
    "k_best = 4\n",
    "km = KMeans(n_clusters=k_best, random_state=RANDOM_STATE, n_init=10)\n",
    "labels_km = km.fit_predict(X_scaled)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_km, s=14)\n",
    "plt.title(f'KMeans (k={k_best}) no espaço PCA 2D')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n",
    "\n",
    "# DBSCAN\n",
    "db = DBSCAN(eps=1.0, min_samples=10)\n",
    "labels_db = db.fit_predict(X_scaled)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=labels_db, s=14)\n",
    "plt.title('DBSCAN no espaço PCA 2D')\n",
    "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "plt.show()\n",
    "\n",
    "# Outliers por IQR em Rendimento\n",
    "Q1 = df['Rendimento'].quantile(0.25)\n",
    "Q3 = df['Rendimento'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lim_inf, lim_sup = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "mask_iqr = (df['Rendimento'] < lim_inf) | (df['Rendimento'] > lim_sup)\n",
    "print('Outliers (IQR) em Rendimento:', mask_iqr.sum())\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(df['Rendimento'])\n",
    "plt.title('Boxplot de Rendimento (IQR)')\n",
    "plt.ylabel('t/ha')\n",
    "plt.show()\n",
    "\n",
    "# IsolationForest em features (sem Cultura)\n",
    "iso = IsolationForest(random_state=RANDOM_STATE, contamination=0.05)\n",
    "out_iso = iso.fit_predict(X_unsup.drop(columns=['Rendimento']))\n",
    "mask_iso = out_iso == -1\n",
    "print('Outliers (IsolationForest):', mask_iso.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b579579",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Preparação para Modelagem Supervisionada (Regressão)\n",
    "Transformação de **Cultura** por One-Hot e padronização de numéricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'Rendimento'\n",
    "features_sup = ['Cultura', 'Precipitação (mm dia 1)',\n",
    "                'Umidade específica a 2 metros (g/kg)',\n",
    "                'Umidade relativa a 2 metros (%)',\n",
    "                'Temperatura a 2 metros (ºC)']\n",
    "\n",
    "X = df[features_sup].copy()\n",
    "y = df[target].values\n",
    "\n",
    "# Colunas\n",
    "cat_cols = ['Cultura']\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "# Transformadores\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc3ed0",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Modelagem: 5 Algoritmos de Regressão\n",
    "Avaliamos com **MAE**, **RMSE** e **R²**, usando `KFold` e depois **avaliamos no hold-out** (teste).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb914464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0, random_state=RANDOM_STATE),\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=RANDOM_STATE),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=7),\n",
    "    # Extra: 'SVR': SVR(), 'ElasticNet': ElasticNet(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "results = []\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[('prep', preprocessor), ('model', model)])\n",
    "    cv_mae = -cross_val_score(pipe, X, y, cv=kf, scoring='neg_mean_absolute_error')\n",
    "    cv_rmse = np.sqrt(-cross_val_score(pipe, X, y, cv=kf, scoring='neg_mean_squared_error'))\n",
    "    cv_r2 = cross_val_score(pipe, X, y, cv=kf, scoring='r2')\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    row = {\n",
    "        'modelo': name,\n",
    "        'cv_mae_mean': cv_mae.mean(),\n",
    "        'cv_rmse_mean': cv_rmse.mean(),\n",
    "        'cv_r2_mean': cv_r2.mean(),\n",
    "        'test_mae': mean_absolute_error(y_test, preds),\n",
    "        'test_rmse': rmse(y_test, preds),\n",
    "        'test_r2': r2_score(y_test, preds)\n",
    "    }\n",
    "    results.append(row)\n",
    "\n",
    "metrics_df = pd.DataFrame(results).sort_values('test_rmse')\n",
    "metrics_path = ARTIFACTS_DIR / 'metrics.csv'\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bee012",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Seleção do Melhor Modelo e Exportação\n",
    "Selecionamos o **menor RMSE de teste**. Salvamos o `Pipeline` completo em `models/best_model.pkl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_name = metrics_df.iloc[0]['modelo']\n",
    "best_model = models[best_name]\n",
    "best_pipe = Pipeline(steps=[('prep', preprocessor), ('model', best_model)])\n",
    "best_pipe.fit(X, y)\n",
    "\n",
    "best_model_path = MODELS_DIR / 'best_model.pkl'\n",
    "joblib.dump(best_pipe, best_model_path)\n",
    "\n",
    "print('Melhor modelo:', best_name)\n",
    "print('Salvo em:', best_model_path)\n",
    "\n",
    "# Predições no conjunto completo para auditoria\n",
    "preds_all = best_pipe.predict(X)\n",
    "audit_df = df.copy()\n",
    "audit_df['Predito (t/ha)'] = preds_all\n",
    "audit_path = ARTIFACTS_DIR / 'predicoes_completas.csv'\n",
    "audit_df.to_csv(audit_path, index=False)\n",
    "audit_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2b15f",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Interpretabilidade (Importâncias de Atributos — quando aplicável)\n",
    "Para modelos baseados em árvore, exibimos importâncias aproximadas para **features numéricas**. (As dummies de `Cultura` são agregadas por média, apenas para ilustração simples.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_importances_from_pipeline(pipe, feature_names):\n",
    "    model = pipe.named_steps['model']\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        plt.figure()\n",
    "        plt.bar(range(len(importances)), importances)\n",
    "        plt.title('Importâncias do Modelo (índices do espaço transformado)')\n",
    "        plt.xlabel('Índice de feature transformada')\n",
    "        plt.ylabel('Importância')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('O modelo não expõe feature_importances_.')\n",
    "\n",
    "# Treinar um pipe específico com RandomForest para visualizar importâncias\n",
    "rf_pipe = Pipeline(steps=[('prep', preprocessor), ('model', RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE))])\n",
    "rf_pipe.fit(X, y)\n",
    "plot_feature_importances_from_pipeline(rf_pipe, features_sup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdca571",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Conclusões e Próximos Passos\n",
    "- **Tendências:** clusters revelam grupos com diferentes perfis de clima/solo e rendimento.\n",
    "- **Outliers:** IQR e IsolationForest ajudam a sinalizar cenários atípicos para inspeção.\n",
    "- **Modelos:** comparamos **5 algoritmos**; o melhor foi salvo para uso futuro.\n",
    "- **Próximos passos (sugestões):**\n",
    "  - Experimentar **otimização de hiperparâmetros** (`GridSearchCV`/`RandomizedSearchCV`).\n",
    "  - Avaliar **MAPE** e faixas de confiança.\n",
    "  - Incluir variáveis adicionais (ex.: fertilização, variedade, pragas).\n",
    "  - Produzir uma API simples (FastAPI) para servir o modelo (link com **Entrega 2: Nuvem**).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
